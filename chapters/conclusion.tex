In this thesis, a sequence-to-sequence model with an attention mechanism was trained on the task of automatic error correction in source code. Experiments on the architecture of the model were conducted revealing the attention mechanism to be an essential part of the model which can not be omitted. Models without the attention mechanism weren't even able to solve the given task. The experiments also showed that an LSTM network outperforms both a vanilla RNN network and a GRU network on this task most likely because it has more trainable parameters.

The errors on which the model was trained were self-introduced into a dataset of correct Java code and ranged from simple syntax errors to more sophisticated semantic ones. The problem of automatically generating logic errors was discussed and it was attempted to introduce such errors into the dataset by switching the order of two adjacent lines in the code. The model managed to achieve promising results on all of the corruptions and further analysis of the errors showed that the performance of the model could even be further improved with additional training. The analysis also showed that the model achieved some understanding of the semantics of source code and how code works.

Alas, this thesis was not able to answer the question if a neural network can detect and correct logic errors. The switching of lines proved to be an insufficient corruption and didn't manage to consistently generate logic errors. On the contrary, most of the errors introduced were semantic ones which the model learned to correct successfully. However, this corruption also confused the model because sometimes these line switches would not introduce any error and because of that the model was unable to learn how to correct these inputs.

\section{Future Work}

The model in this thesis has proven to be able to correct syntax and semantic errors. As mentioned it still remains to be seen if it can also detect and correct logic errors. To test this a different corruption has to be found which introduces logic errors more consistently into the dataset. An even better alternative would be the collection of a dataset of real-life examples. With that, the model could be evaluated on its performance on a big variety of non-artificial errors and one would most likely get a deeper insight into the possibilities and limitations of this model.

For this thesis, the model was trained on Java which is a strongly typed language. Future work could also include applying the same techniques to a weakly typed language. Errors in weakly typed languages are harder to spot which could bring some additional insights. This could also have some real-life applications because IDEs today are still not able to spot most errors in weakly typed languages.
